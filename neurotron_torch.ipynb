{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ep5SeJ5qte9A",
      "metadata": {
        "id": "ep5SeJ5qte9A"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b3ddc0-c342-4c4c-950f-c2d849abda98",
      "metadata": {
        "id": "91b3ddc0-c342-4c4c-950f-c2d849abda98"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection  import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "xZfcrdxetcZ8",
      "metadata": {
        "id": "xZfcrdxetcZ8"
      },
      "source": [
        "# The NeuroTron class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a576bbe-9c31-4b25-bd86-da48a12ec29d",
      "metadata": {
        "id": "0a576bbe-9c31-4b25-bd86-da48a12ec29d"
      },
      "outputs": [],
      "source": [
        "class NeuroTron(nn.Module):\n",
        "    def __init__(self, n, r, h, activation=nn.functional.relu, w_init='const', dtype=torch.float32):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            n: number of input features\n",
        "            r: number of parameters\n",
        "            h: hidden layer width\n",
        "            activation: activation function\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.w = nn.Parameter(torch.empty(r, dtype=dtype), requires_grad=False)\n",
        "        \n",
        "        self.M = torch.randn(r, n, dtype=dtype)\n",
        "        self.set_A(n, r, h, dtype=dtype)\n",
        "\n",
        "        self.set_w(w_init)\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "    def set_A(self, n, r, h, dtype=torch.float32):\n",
        "        self.A = torch.empty(h, r, n, dtype=dtype)\n",
        "\n",
        "        C = torch.randn(r, n, dtype=dtype)\n",
        "\n",
        "        k = h // 2\n",
        "        i = 0\n",
        "\n",
        "        for factor in range(-k, k+1):\n",
        "            if factor != 0:\n",
        "                Z = self.M + factor * C\n",
        "                self.A[i, :, :] = Z\n",
        "                i += 1\n",
        "\n",
        "    def set_w(self, init):\n",
        "        if init == 'const':\n",
        "            nn.init.constant_(self.w, 1.)\n",
        "        elif init == 'unif':\n",
        "            nn.init.uniform_(self.w)\n",
        "\n",
        "    def num_A(self):\n",
        "        return self.A.shape[0]\n",
        "\n",
        "    def forward(self, x):\n",
        "        postactivation = 0.\n",
        "        for i in range(self.num_A()):\n",
        "            preactivation = torch.matmul(torch.matmul(self.w, self.A[i, :, :]), x.t())\n",
        "            postactivation += self.activation(preactivation)\n",
        "        return postactivation / self.num_A()\n",
        "\n",
        "    def gradient(self, x, output, y):\n",
        "        return torch.matmul(self.M, torch.matmul(y - output, x) / x.shape[0])\n",
        "\n",
        "    def update_parameters(self, x, output, y, stepsize):\n",
        "        self.w.data.add_(stepsize * self.gradient(x, output, y))\n",
        "\n",
        "    def train(self, train_loader, test_loader, stepsize, loss, log_step=200):\n",
        "        train_losses, test_losses = [], []\n",
        "\n",
        "        for train_batch_idx, (train_data, train_targets) in enumerate(train_loader):\n",
        "            train_output = self.forward(train_data)\n",
        "\n",
        "            self.update_parameters(train_data, train_output, train_targets, stepsize)\n",
        "\n",
        "            if (train_batch_idx % log_step == 0):\n",
        "                train_losses.append(loss(train_targets, train_output))\n",
        "\n",
        "                test_loss = 0.\n",
        "\n",
        "                for test_batch_idx, (test_data, test_targets) in enumerate(test_loader):\n",
        "                    test_output = self.forward(test_data)\n",
        "\n",
        "                    test_loss += loss(test_targets, test_output)\n",
        "\n",
        "                test_loss /= len(test_loader)\n",
        "\n",
        "                test_losses.append(test_loss)\n",
        "\n",
        "        return torch.stack(train_losses), torch.stack(test_losses)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5244cde6",
      "metadata": {},
      "source": [
        "# The PoisonedDataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86397858-92c7-4ef6-9a36-e19ee6944601",
      "metadata": {
        "id": "86397858-92c7-4ef6-9a36-e19ee6944601"
      },
      "outputs": [],
      "source": [
        "class PoisonedDataset(Dataset):\n",
        "    def __init__(self, x, y, beta, theta):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.beta = beta\n",
        "        self.theta = theta\n",
        "\n",
        "    def attack(self, y):\n",
        "        a = torch.bernoulli(torch.full_like(y, self.beta))\n",
        "        xi = torch.distributions.uniform.Uniform(torch.full_like(y, -self.theta), torch.full_like(y, self.theta)).sample()\n",
        "\n",
        "        return y + a * xi\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'PoisonedDataset'\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i], self.attack(self.y[i])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b0fafefa",
      "metadata": {},
      "source": [
        "# Standard normal example"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b26537ff",
      "metadata": {},
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fbb35f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "abs_bound = 1.\n",
        "num_samples = 100\n",
        "num_features = 2\n",
        "\n",
        "sampling_distribution = torch.distributions.multivariate_normal.MultivariateNormal(\n",
        "    torch.zeros(num_features, dtype=torch.float32), torch.eye(num_features, dtype=torch.float32)\n",
        ")\n",
        "\n",
        "normal_data = sampling_distribution.sample([num_samples])\n",
        "\n",
        "normal_targets = torch.stack([sampling_distribution.log_prob(normal_data[i, :]).exp() for i in range(num_samples)], dim=0)\n",
        "\n",
        "# print(normal_data.shape, normal_targets.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8bddba2",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(normal_data, normal_targets, test_size=0.25)\n",
        "\n",
        "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d164ac12",
      "metadata": {},
      "outputs": [],
      "source": [
        "beta = 0.5\n",
        "theta = 0.125\n",
        "\n",
        "train_dataset = PoisonedDataset(x_train, y_train, beta=beta, theta=theta)\n",
        "test_dataset = PoisonedDataset(x_test, y_test, beta=beta, theta=theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43eb1e0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6b729bc1",
      "metadata": {},
      "source": [
        "## Instantiate NeuroTron class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a621b05",
      "metadata": {},
      "outputs": [],
      "source": [
        "neurotron = NeuroTron(n=num_features, r=25, h=10, dtype=torch.float32)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c3851ee7",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707509fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_losses_in_epoch, test_losses_in_epoch = neurotron.train(\n",
        "        train_loader, test_loader, stepsize=0.0001, loss=nn.MSELoss(reduction='mean'), log_step=2\n",
        "    )\n",
        "\n",
        "    train_losses.append(train_losses_in_epoch)\n",
        "    test_losses.append(test_losses_in_epoch)\n",
        "\n",
        "train_losses = torch.stack(train_losses, dim=0)\n",
        "test_losses = torch.stack(test_losses, dim=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6e6ef080",
      "metadata": {},
      "source": [
        "## Plotting training and test loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03bb8772",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(torch.flatten(train_losses), label=\"Train loss\")\n",
        "plt.plot(torch.flatten(test_losses), label=\"Test loss\")\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ec275a91",
      "metadata": {},
      "source": [
        "# California housing example"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "BJhuXtb4tSGm",
      "metadata": {
        "id": "BJhuXtb4tSGm"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2ff6a2-ea0e-445d-83f6-35cb3d9286d4",
      "metadata": {
        "id": "fe2ff6a2-ea0e-445d-83f6-35cb3d9286d4"
      },
      "outputs": [],
      "source": [
        "california_housing = fetch_california_housing(as_frame=True)\n",
        "\n",
        "# california_housing.frame\n",
        "# california_housing.data\n",
        "# california_housing.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b536b36-e3a6-495d-8708-2c3a093d8a2c",
      "metadata": {
        "id": "8b536b36-e3a6-495d-8708-2c3a093d8a2c"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(california_housing.data, california_housing.target, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e310e568",
      "metadata": {
        "id": "e310e568"
      },
      "outputs": [],
      "source": [
        "x_train = StandardScaler().fit_transform(x_train.to_numpy(dtype=np.float32))\n",
        "x_test = StandardScaler().fit_transform(x_test.to_numpy(dtype=np.float32))\n",
        "\n",
        "y_train = y_train.to_numpy(dtype=np.float32)\n",
        "y_test = y_test.to_numpy(dtype=np.float32)\n",
        "\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2a1abf-c907-4b3e-b47d-a566fa09aa74",
      "metadata": {
        "id": "8c2a1abf-c907-4b3e-b47d-a566fa09aa74"
      },
      "outputs": [],
      "source": [
        "beta = 0.\n",
        "theta = 0.01\n",
        "\n",
        "train_dataset = PoisonedDataset(torch.from_numpy(x_train), torch.from_numpy(y_train), beta=beta, theta=theta)\n",
        "test_dataset = PoisonedDataset(torch.from_numpy(x_test), torch.from_numpy(y_test), beta=beta, theta=theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0600652c",
      "metadata": {
        "id": "0600652c"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "rW48ls14tPZG",
      "metadata": {
        "id": "rW48ls14tPZG"
      },
      "source": [
        "## Instantiate NeuroTron class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9d754b",
      "metadata": {
        "id": "5b9d754b"
      },
      "outputs": [],
      "source": [
        "neurotron = NeuroTron(n=8, r=6, h=10, dtype=torch.float32)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6a79aa6d",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc541837",
      "metadata": {
        "id": "fc541837"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_losses_in_epoch, test_losses_in_epoch = neurotron.train(\n",
        "        train_loader, test_loader, stepsize=0.00001, loss=nn.MSELoss(reduction='mean'), log_step=2\n",
        "    )\n",
        "\n",
        "    train_losses.append(train_losses_in_epoch)\n",
        "    test_losses.append(test_losses_in_epoch)\n",
        "\n",
        "train_losses = torch.stack(train_losses, dim=0)\n",
        "test_losses = torch.stack(test_losses, dim=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6238f655",
      "metadata": {},
      "source": [
        "## Plotting training and test loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696d1a54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "696d1a54",
        "outputId": "25d6915e-370f-40f2-fac8-156191c666b2"
      },
      "outputs": [],
      "source": [
        "plt.plot(torch.flatten(train_losses), label=\"Train loss\")\n",
        "plt.plot(torch.flatten(test_losses), label=\"Test loss\")\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dIyEmIdjPGGz",
      "metadata": {
        "id": "dIyEmIdjPGGz"
      },
      "source": [
        "## Printing dimensions of various tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1757f0c",
      "metadata": {
        "id": "b1757f0c"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gBL--VYSOc1N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBL--VYSOc1N",
        "outputId": "2ccc4d00-b370-4472-a50f-91047f7c3569"
      },
      "outputs": [],
      "source": [
        "x.shape, x.shape[0], x.shape[1], y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "At_bveAyOewG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At_bveAyOewG",
        "outputId": "7a00c0a0-6577-4ba5-e14e-395174d4aee0"
      },
      "outputs": [],
      "source": [
        "neurotron.w.shape, neurotron.A.shape, neurotron.M.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EXNwqkrNO9mI",
      "metadata": {
        "id": "EXNwqkrNO9mI"
      },
      "outputs": [],
      "source": [
        "output = neurotron.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6LZJ9bNtPa2o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LZJ9bNtPa2o",
        "outputId": "b6319fa4-40e3-4cef-c4c0-ee7893c3a1ae"
      },
      "outputs": [],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J6_NVvvBPoaS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6_NVvvBPoaS",
        "outputId": "0e753920-c382-4dac-910b-0f6e505ebe70"
      },
      "outputs": [],
      "source": [
        "neurotron.w.shape, neurotron.A[0, :, :].shape, x.t().shape, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EgykbPv4PdHn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgykbPv4PdHn",
        "outputId": "227991e0-29d9-49c7-b56e-d554767e35e4"
      },
      "outputs": [],
      "source": [
        "torch.matmul(neurotron.w, neurotron.A[0, :, :]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mUtr3JJsP6i1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUtr3JJsP6i1",
        "outputId": "5f814967-e55b-4369-f926-c437352a8d55"
      },
      "outputs": [],
      "source": [
        "torch.matmul(torch.matmul(neurotron.w, neurotron.A[0, :, :]), x.t()).shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "jupyterlab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "cead0af08cc8bb7845d5c8257e3cb30f773de23decc86928a996939ac684776b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
